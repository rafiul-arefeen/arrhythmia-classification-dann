{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "799cb16f",
      "metadata": {
        "id": "799cb16f"
      },
      "source": [
        "# Combined ECG Pipeline: MIT-BIH (3-class, 2-lead) & INCART (2-lead subset to match MIT-BIH)\n",
        "\n",
        "This notebook merges the workflows from your two notebooks:\n",
        "\n",
        "- **MIT-BIH:** start from raw WFDB records → extract two leads → map to **3 classes (N/S/V)** → segment around R-peaks → **SMOTE** → train.\n",
        "- **INCART:** select **two leads analogous to MIT-BIH** (Lead II + V1 if available, otherwise V5) → map to **3 classes (N/S/V)** → segment around R-peaks → **SMOTE** → train.\n",
        "\n",
        "It uses a **shared model** (1D CNN + BatchNorm) and produces comparable metrics for each dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d00775d4",
      "metadata": {
        "id": "d00775d4"
      },
      "source": [
        "## Requirements\n",
        "\n",
        "Run the cell below if you're in a fresh environment (e.g., Colab). If packages are already installed, you can skip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4a0734",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4a0734",
        "outputId": "363b1c4c-1581-4fbf-d9a8-144989b57639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb==4.1.2\n",
            "  Using cached wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting imbalanced-learn==0.12.2\n",
            "  Using cached imbalanced_learn-0.12.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15.0 (from versions: 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0, 2.18.1, 2.19.0rc0, 2.19.0, 2.19.1, 2.20.0rc0, 2.20.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# If running in Colab or a minimal environment, uncomment these:\n",
        "!pip install wfdb==4.1.2 imbalanced-learn==0.12.2 numpy pandas scipy scikit-learn tensorflow==2.15.0 matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TI6HbMGIWYFf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI6HbMGIWYFf",
        "outputId": "43467f4a-0d61-4923-a141-587959ba6e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "Requirement already satisfied: tensorflow<2.21,>=2.18 in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.12/dist-packages (4.3.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.21,>=2.18) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.18) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.18) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.18) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.18) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.21,>=2.18) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.21,>=2.18) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.21,>=2.18) (3.1.3)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.12.15)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.18) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.21,>=2.18) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.21,>=2.18) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.21,>=2.18) (0.17.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.21,>=2.18) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.21,>=2.18) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.21,>=2.18) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.21,>=2.18) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# upgrade pip first (often fixes resolver issues)\n",
        "!pip install -U pip\n",
        "\n",
        "# TensorFlow 2.18–2.20 works with this notebook\n",
        "!pip install \"tensorflow>=2.18,<2.21\" wfdb imbalanced-learn numpy pandas scipy scikit-learn matplotlib\n",
        "# Optional GPU build on supported NVIDIA setups:\n",
        "# pip install \"tensorflow[and-cuda]>=2.18,<2.21\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UeBU0ARlVp_H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeBU0ARlVp_H",
        "outputId": "0c150e1d-fc38-42ce-9117-797cd5c1f14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a2adfa7",
      "metadata": {
        "id": "2a2adfa7"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "- **Data locations:** point `MITBIH_DIR` and `INCART_DIR` to folders with WFDB records (`.dat/.hea`) and annotations (`atr`).\n",
        "- **Leads:** We harmonize to **Lead II** + **V1** if available (fallback to **V5**).\n",
        "- **Classes:** 3-class mapping (N/S/V) per AAMI-style grouping.\n",
        "\n",
        "The pipeline:\n",
        "1. Auto-detect records in each folder (or specify lists).\n",
        "2. Resample each record to a shared sample rate (`TARGET_FS`) for consistent window sizes across datasets.\n",
        "3. Extract R-peak–centered windows per beat with z-score normalization.\n",
        "4. Map beat symbols to `{'N','S','V'}`; drop others.\n",
        "5. Split (patient/record-wise) into **train/test** (configurable).\n",
        "6. **Apply SMOTE to train only** (flatten → SMOTE → reshape).\n",
        "7. Train a shared **1D CNN + BatchNorm** and evaluate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91d2d43b",
      "metadata": {
        "id": "91d2d43b"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "from scipy.signal import resample_poly\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# USER CONFIG\n",
        "MITBIH_DIR = \"/content/drive/MyDrive/ml project/data/mitdb\"  # <-- change to your MIT-BIH data folder\n",
        "INCART_DIR = \"/content/drive/MyDrive/ml project/data/incart\"   # <-- change to your INCART data folder\n",
        "\n",
        "MITBIH_RECORDS = None  # e.g., ['100','101','102', ...]\n",
        "INCART_RECORDS = None  # e.g., ['I01','I02', ...]\n",
        "\n",
        "TARGET_FS = 360  # MIT-BIH is 360 Hz; INCART will be upsampled from ~257 Hz\n",
        "PRE_SEC  = 0.20\n",
        "POST_SEC = 0.40\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "LOGDIR = \"logs/ecg_joint\"\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "PRIMARY_LEAD_NAMES = ['MLII', 'II', 'Lead II', 'lead_II', 'le II', 'le2']\n",
        "SECONDARY_LEAD_PRIORITY = ['V1', 'V5']\n",
        "\n",
        "N_SET = set(list(\"NLRej\"))\n",
        "S_SET = set(['A','a','J','S'])\n",
        "V_SET = set(['V','E'])\n",
        "\n",
        "def symbol_to_class(sym):\n",
        "    if sym in N_SET:\n",
        "        return 'N'\n",
        "    if sym in S_SET:\n",
        "        return 'S'\n",
        "    if sym in V_SET:\n",
        "        return 'V'\n",
        "    return None\n",
        "\n",
        "CLASS_ORDER = ['N','S','V']\n",
        "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASS_ORDER)}\n",
        "IDX_TO_CLASS = {i:c for c,i in CLASS_TO_IDX.items()}\n",
        "\n",
        "def one_hot(y_idx, num_classes=3):\n",
        "    return utils.to_categorical(y_idx, num_classes=num_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e7fc66b",
      "metadata": {
        "id": "0e7fc66b"
      },
      "source": [
        "## Utilities: Lead Selection, Resampling, Segmentation, and Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ed38fa9",
      "metadata": {
        "id": "7ed38fa9"
      },
      "outputs": [],
      "source": [
        "def pick_two_leads(signal_names):\n",
        "    # Choose two leads analogous to MIT-BIH: primary = II/MLII; secondary = V1, fallback V5, else any V*\n",
        "    names = list(signal_names)\n",
        "    # Primary\n",
        "    primary_idx = None\n",
        "    for alias in PRIMARY_LEAD_NAMES:\n",
        "        if alias in names:\n",
        "            primary_idx = names.index(alias)\n",
        "            break\n",
        "    if primary_idx is None:\n",
        "        for i, nm in enumerate(names):\n",
        "            if nm.strip().upper() in ['MLII','II','LEAD II','LEAD_II']:\n",
        "                primary_idx = i\n",
        "                break\n",
        "    if primary_idx is None:\n",
        "        raise ValueError(f\"Primary lead (II/MLII) not found in {names}\")\n",
        "    # Secondary\n",
        "    secondary_idx = None\n",
        "    for sec in SECONDARY_LEAD_PRIORITY:\n",
        "        if sec in names:\n",
        "            secondary_idx = names.index(sec)\n",
        "            break\n",
        "    if secondary_idx is None:\n",
        "        for i, nm in enumerate(names):\n",
        "            if nm.strip().upper().startswith('V'):\n",
        "                secondary_idx = i\n",
        "                break\n",
        "    if secondary_idx is None:\n",
        "        raise ValueError(f\"No chest lead (V1/V5/any V*) found in {names}\")\n",
        "    if secondary_idx == primary_idx:\n",
        "        for i, nm in enumerate(names):\n",
        "            if i != primary_idx and nm.strip().upper().startswith('V'):\n",
        "                secondary_idx = i\n",
        "                break\n",
        "    return primary_idx, secondary_idx\n",
        "\n",
        "def resample_to_target(sig, fs, target_fs=TARGET_FS):\n",
        "    if fs == target_fs:\n",
        "        return sig\n",
        "    from fractions import Fraction\n",
        "    frac = Fraction(target_fs, int(fs)).limit_denominator(1000)\n",
        "    up, down = frac.numerator, frac.denominator\n",
        "    return resample_poly(sig, up, down)\n",
        "\n",
        "def extract_windows(signals, ann_samples, ann_symbols, fs, pre_sec=PRE_SEC, post_sec=POST_SEC):\n",
        "    pre = int(round(pre_sec * fs))\n",
        "    post = int(round(post_sec * fs))\n",
        "    win_len = pre + post\n",
        "    X_list, y_list = [], []\n",
        "    n = signals.shape[0]\n",
        "    for s, sym in zip(ann_samples, ann_symbols):\n",
        "        cls = symbol_to_class(sym)\n",
        "        if cls is None:\n",
        "            continue\n",
        "        start = s - pre\n",
        "        end = s + post\n",
        "        if start < 0 or end > n:\n",
        "            continue\n",
        "        seg = signals[start:end, :]\n",
        "        seg = (seg - seg.mean(axis=0, keepdims=True)) / (seg.std(axis=0, keepdims=True) + 1e-6)\n",
        "        X_list.append(seg.astype(np.float32))\n",
        "        y_list.append(CLASS_TO_IDX[cls])\n",
        "    if not X_list:\n",
        "        return np.empty((0, win_len, 2), dtype=np.float32), np.empty((0,), dtype=int)\n",
        "    return np.stack(X_list, axis=0), np.array(y_list, dtype=int)\n",
        "\n",
        "def autodetect_records(folder: str):\n",
        "    p = Path(folder)\n",
        "    recs = sorted([f.stem for f in p.glob(\"*.hea\")])\n",
        "    return recs\n",
        "\n",
        "def load_dataset_from_folder(folder, record_ids=None, dataset_name=\"\"):\n",
        "    if record_ids is None:\n",
        "        record_ids = autodetect_records(folder)\n",
        "    X_all, y_all, rec_all = [], [], []\n",
        "    for rid in record_ids:\n",
        "        rec_path = str(Path(folder) / rid)\n",
        "        try:\n",
        "            rec = wfdb.rdrecord(rec_path)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Skipping {rid}: rdrecord failed ({e})\")\n",
        "            continue\n",
        "        sig = rec.p_signal\n",
        "        names = rec.sig_name\n",
        "        fs = rec.fs\n",
        "        try:\n",
        "            i_primary, i_secondary = pick_two_leads(names)\n",
        "        except ValueError as e:\n",
        "            print(f\"[WARN] Skipping {rid}: {e}\")\n",
        "            continue\n",
        "        sig2 = np.stack([sig[:, i_primary], sig[:, i_secondary]], axis=1)\n",
        "        sig2_rs = np.column_stack([\n",
        "            resample_to_target(sig2[:,0], fs, TARGET_FS),\n",
        "            resample_to_target(sig2[:,1], fs, TARGET_FS),\n",
        "        ])\n",
        "        try:\n",
        "            ann = wfdb.rdann(rec_path, 'atr')\n",
        "            ann_samples = np.array(ann.sample, dtype=int)\n",
        "            ann_symbols = np.array(ann.symbol)\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] Skipping {rid}: rdann failed ({e})\")\n",
        "            continue\n",
        "        X_rec, y_rec = extract_windows(sig2_rs, ann_samples, ann_symbols, TARGET_FS)\n",
        "        if X_rec.shape[0] == 0:\n",
        "            print(f\"[INFO] No usable beats for {rid}\")\n",
        "            continue\n",
        "        X_all.append(X_rec)\n",
        "        y_all.append(y_rec)\n",
        "        rec_all.append(np.full(y_rec.shape, fill_value=rid, dtype=object))\n",
        "        print(f\"[OK] {dataset_name} {rid}: beats={X_rec.shape[0]} lead_primary={names[i_primary]} lead_secondary={names[i_secondary]}\")\n",
        "    if not X_all:\n",
        "        return np.empty((0, int(round((PRE_SEC+POST_SEC)*TARGET_FS)), 2), dtype=np.float32), \\\n",
        "               np.empty((0,), dtype=int), np.empty((0,), dtype=object)\n",
        "    X = np.concatenate(X_all, axis=0)\n",
        "    y = np.concatenate(y_all, axis=0)\n",
        "    rec_idx = np.concatenate(rec_all, axis=0)\n",
        "    return X, y, rec_idx\n",
        "\n",
        "def record_wise_split(rec_idx, test_size=TEST_SIZE, random_state=RANDOM_STATE):\n",
        "    import numpy as _np\n",
        "    from sklearn.model_selection import train_test_split as _tts\n",
        "    uniq = _np.unique(rec_idx)\n",
        "    train_recs, test_recs = _tts(uniq, test_size=test_size, random_state=random_state, shuffle=True)\n",
        "    train_mask = _np.isin(rec_idx, train_recs)\n",
        "    test_mask = _np.isin(rec_idx, test_recs)\n",
        "    return train_mask, test_mask\n",
        "\n",
        "def apply_smote(X, y_idx):\n",
        "    N, T, C = X.shape\n",
        "    X_flat = X.reshape(N, T*C)\n",
        "    smote = SMOTE(random_state=RANDOM_STATE)\n",
        "    Xr, yr = smote.fit_resample(X_flat, y_idx)\n",
        "    Xr = Xr.reshape(Xr.shape[0], T, C).astype(np.float32)\n",
        "    return Xr, yr\n",
        "\n",
        "def build_cnn_model(input_shape, num_classes=3):\n",
        "    inp = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv1D(32, 7, padding='same', activation='relu')(inp)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPooling1D(2)(x)\n",
        "    x = tf.keras.layers.Conv1D(64, 5, padding='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.MaxPooling1D(2)(x)\n",
        "    x = tf.keras.layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.3)(x)\n",
        "    out = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inp, out)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def describe_distribution(y_idx, title=\"\"):\n",
        "    import pandas as _pd\n",
        "    import numpy as _np\n",
        "    counts = _pd.Series(y_idx).value_counts().reindex([0,1,2], fill_value=0)\n",
        "    df = _pd.DataFrame({\"class\": [IDX_TO_CLASS[i] for i in counts.index], \"count\": counts.values})\n",
        "    print(\"\\n\"+title)\n",
        "    print(df)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99f76d5c",
      "metadata": {
        "id": "99f76d5c"
      },
      "source": [
        "## MIT-BIH → 3-class, 2-lead → SMOTE → Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4dca34c",
      "metadata": {
        "id": "d4dca34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e1c875-0aae-4dfa-c157-d4cf35fd5138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] MIT-BIH 100: beats=2272 lead_primary=MLII lead_secondary=V5\n",
            "[OK] MIT-BIH 101: beats=1863 lead_primary=MLII lead_secondary=V1\n",
            "[WARN] Skipping 102: Primary lead (II/MLII) not found in ['V5', 'V2']\n",
            "[OK] MIT-BIH 103: beats=2083 lead_primary=MLII lead_secondary=V2\n",
            "[WARN] Skipping 104: Primary lead (II/MLII) not found in ['V5', 'V2']\n",
            "[OK] MIT-BIH 105: beats=2567 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 106: beats=2027 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 107: beats=59 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 108: beats=1761 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 109: beats=2529 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 111: beats=2124 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 112: beats=2538 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 113: beats=1794 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 114: beats=1875 lead_primary=MLII lead_secondary=V5\n",
            "[OK] MIT-BIH 115: beats=1952 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 116: beats=2411 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 117: beats=1534 lead_primary=MLII lead_secondary=V2\n",
            "[OK] MIT-BIH 118: beats=2277 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 119: beats=1987 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 121: beats=1862 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 122: beats=2475 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 123: beats=1517 lead_primary=MLII lead_secondary=V5\n",
            "[OK] MIT-BIH 124: beats=1613 lead_primary=MLII lead_secondary=V4\n",
            "[OK] MIT-BIH 200: beats=2598 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 201: beats=1961 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 202: beats=2134 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 203: beats=2975 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 205: beats=2644 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 207: beats=1859 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 208: beats=2579 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 209: beats=3004 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 210: beats=2638 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 212: beats=2747 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 213: beats=2888 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 214: beats=2257 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 215: beats=3361 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 217: beats=406 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 219: beats=2153 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 220: beats=2046 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 221: beats=2427 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 222: beats=2482 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 223: beats=2591 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 228: beats=2053 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 230: beats=2256 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 231: beats=1570 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 232: beats=1780 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 233: beats=3066 lead_primary=MLII lead_secondary=V1\n",
            "[OK] MIT-BIH 234: beats=2753 lead_primary=MLII lead_secondary=V1\n",
            "MIT-BIH shapes: (100348, 216, 2) (100348,)\n",
            "\n",
            "MIT-BIH Train (pre-SMOTE)\n",
            "  class  count\n",
            "0     N  69507\n",
            "1     S   2584\n",
            "2     V   5018\n",
            "\n",
            "MIT-BIH Test\n",
            "  class  count\n",
            "0     N  20831\n",
            "1     S    197\n",
            "2     V   2211\n",
            "\n",
            "MIT-BIH Train (post-SMOTE)\n",
            "  class  count\n",
            "0     N  69507\n",
            "1     S  69507\n",
            "2     V  69507\n",
            "Saved -> mitbih_3class_2lead.npz\n",
            "Epoch 1/25\n",
            "1385/1385 - 90s - 65ms/step - accuracy: 0.9526 - loss: 0.1337 - val_accuracy: 0.9931 - val_loss: 0.0202\n",
            "Epoch 2/25\n",
            "1385/1385 - 85s - 62ms/step - accuracy: 0.9802 - loss: 0.0582 - val_accuracy: 0.9882 - val_loss: 0.0357\n",
            "Epoch 3/25\n",
            "1385/1385 - 86s - 62ms/step - accuracy: 0.9867 - loss: 0.0397 - val_accuracy: 0.9812 - val_loss: 0.0560\n",
            "Epoch 4/25\n",
            "1385/1385 - 141s - 102ms/step - accuracy: 0.9894 - loss: 0.0317 - val_accuracy: 0.9970 - val_loss: 0.0081\n",
            "Epoch 5/25\n",
            "1385/1385 - 149s - 108ms/step - accuracy: 0.9917 - loss: 0.0253 - val_accuracy: 0.9937 - val_loss: 0.0188\n",
            "Epoch 6/25\n",
            "1385/1385 - 138s - 99ms/step - accuracy: 0.9930 - loss: 0.0216 - val_accuracy: 0.9963 - val_loss: 0.0105\n",
            "Epoch 7/25\n",
            "1385/1385 - 145s - 105ms/step - accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9986 - val_loss: 0.0041\n",
            "Epoch 8/25\n",
            "1385/1385 - 91s - 66ms/step - accuracy: 0.9945 - loss: 0.0166 - val_accuracy: 0.9994 - val_loss: 0.0017\n",
            "Epoch 9/25\n",
            "1385/1385 - 141s - 102ms/step - accuracy: 0.9951 - loss: 0.0148 - val_accuracy: 0.9997 - val_loss: 9.1224e-04\n",
            "Epoch 10/25\n",
            "1385/1385 - 145s - 105ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
            "Epoch 11/25\n",
            "1385/1385 - 139s - 100ms/step - accuracy: 0.9959 - loss: 0.0127 - val_accuracy: 0.9997 - val_loss: 9.9785e-04\n",
            "Epoch 12/25\n",
            "1385/1385 - 87s - 63ms/step - accuracy: 0.9963 - loss: 0.0113 - val_accuracy: 0.9967 - val_loss: 0.0089\n",
            "Epoch 13/25\n",
            "1385/1385 - 145s - 105ms/step - accuracy: 0.9964 - loss: 0.0108 - val_accuracy: 0.9987 - val_loss: 0.0033\n",
            "Epoch 14/25\n",
            "1385/1385 - 150s - 109ms/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9982 - val_loss: 0.0048\n",
            "Epoch 15/25\n",
            "1385/1385 - 143s - 103ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.9980 - val_loss: 0.0066\n",
            "Epoch 16/25\n",
            "1385/1385 - 137s - 99ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.9998 - val_loss: 4.4536e-04\n",
            "Epoch 17/25\n",
            "1385/1385 - 98s - 71ms/step - accuracy: 0.9974 - loss: 0.0079 - val_accuracy: 0.9991 - val_loss: 0.0029\n",
            "Epoch 18/25\n",
            "1385/1385 - 138s - 100ms/step - accuracy: 0.9975 - loss: 0.0080 - val_accuracy: 0.9988 - val_loss: 0.0035\n",
            "Epoch 19/25\n",
            "1385/1385 - 141s - 102ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
            "Epoch 20/25\n",
            "1385/1385 - 92s - 67ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9999 - val_loss: 7.7201e-04\n",
            "Epoch 21/25\n",
            "1385/1385 - 145s - 105ms/step - accuracy: 0.9977 - loss: 0.0072 - val_accuracy: 0.9996 - val_loss: 0.0015\n",
            "Epoch 22/25\n",
            "1385/1385 - 142s - 102ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9997 - val_loss: 5.2641e-04\n",
            "Epoch 23/25\n",
            "1385/1385 - 101s - 73ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9999 - val_loss: 4.2349e-04\n",
            "Epoch 24/25\n",
            "1385/1385 - 96s - 70ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9999 - val_loss: 4.5456e-04\n",
            "Epoch 25/25\n",
            "1385/1385 - 140s - 101ms/step - accuracy: 0.9982 - loss: 0.0057 - val_accuracy: 0.9999 - val_loss: 5.1448e-04\n",
            "MIT-BIH Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N     0.9931    0.6916    0.8153     20831\n",
            "           S     0.0053    0.0660    0.0099       197\n",
            "           V     0.3357    0.9557    0.4968      2211\n",
            "\n",
            "    accuracy                         0.7114     23239\n",
            "   macro avg     0.4447    0.5711    0.4407     23239\n",
            "weighted avg     0.9222    0.7114    0.7782     23239\n",
            "\n",
            "Confusion Matrix:\n",
            "[[14406  2405  4020]\n",
            " [   22    13   162]\n",
            " [   78    20  2113]]\n"
          ]
        }
      ],
      "source": [
        "# Load MIT-BIH\n",
        "mit_X, mit_y, mit_rec = load_dataset_from_folder(MITBIH_DIR, MITBIH_RECORDS, dataset_name=\"MIT-BIH\")\n",
        "win_len = mit_X.shape[1] if mit_X.size > 0 else int(round((PRE_SEC+POST_SEC)*TARGET_FS))\n",
        "print(\"MIT-BIH shapes:\", mit_X.shape, mit_y.shape)\n",
        "\n",
        "# Split by record\n",
        "mit_train_mask, mit_test_mask = record_wise_split(mit_rec)\n",
        "Xtr_mit, ytr_mit = mit_X[mit_train_mask], mit_y[mit_train_mask]\n",
        "Xte_mit, yte_mit = mit_X[mit_test_mask], mit_y[mit_test_mask]\n",
        "\n",
        "describe_distribution(ytr_mit, \"MIT-BIH Train (pre-SMOTE)\")\n",
        "describe_distribution(yte_mit, \"MIT-BIH Test\")\n",
        "\n",
        "# Apply SMOTE to train only\n",
        "if Xtr_mit.shape[0] > 0:\n",
        "    Xtr_mit_sm, ytr_mit_sm = apply_smote(Xtr_mit, ytr_mit)\n",
        "    describe_distribution(ytr_mit_sm, \"MIT-BIH Train (post-SMOTE)\")\n",
        "else:\n",
        "    Xtr_mit_sm, ytr_mit_sm = Xtr_mit, ytr_mit\n",
        "    print(\"[WARN] No MIT-BIH training beats; SMOTE skipped.\")\n",
        "\n",
        "# Save preprocessed datasets\n",
        "np.savez_compressed(\"mitbih_3class_2lead.npz\",\n",
        "                    X_train=Xtr_mit_sm, y_train=ytr_mit_sm,\n",
        "                    X_test=Xte_mit, y_test=yte_mit, rec_test=mit_rec[mit_test_mask])\n",
        "print(\"Saved -> mitbih_3class_2lead.npz\")\n",
        "\n",
        "# Build & train model\n",
        "mit_model = build_cnn_model(input_shape=(win_len, 2), num_classes=3)\n",
        "tb = tf.keras.callbacks.TensorBoard(log_dir=str(Path(LOGDIR) / \"mitbih\"), histogram_freq=0)\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "if Xtr_mit_sm.shape[0] > 0:\n",
        "    mit_hist = mit_model.fit(\n",
        "        Xtr_mit_sm, one_hot(ytr_mit_sm, 3),\n",
        "        validation_split=0.15,\n",
        "        epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "        callbacks=[tb, es], verbose=2\n",
        "    )\n",
        "else:\n",
        "    print(\"[WARN] MIT-BIH training skipped (no data).\")\n",
        "\n",
        "# Evaluate\n",
        "if Xte_mit.shape[0] > 0:\n",
        "    yhat = mit_model.predict(Xte_mit, verbose=0).argmax(axis=1)\n",
        "    print(\"MIT-BIH Classification Report:\")\n",
        "    print(classification_report(yte_mit, yhat, target_names=CLASS_ORDER, digits=4))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(yte_mit, yhat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2c434f",
      "metadata": {
        "id": "8a2c434f"
      },
      "source": [
        "## INCART → 2-lead subset (II + V1/V5) → 3-class → SMOTE → Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b79b962",
      "metadata": {
        "id": "0b79b962",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55254cb-37ec-4801-e498-7f2ae7635d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] INCART I01: beats=2757 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I02: beats=2673 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I03: beats=2451 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I04: beats=2406 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I05: beats=1767 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I06: beats=2493 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I07: beats=2705 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I08: beats=2129 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I09: beats=2988 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I10: beats=3682 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I11: beats=2081 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I12: beats=2807 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I13: beats=2023 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I14: beats=1865 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I15: beats=2634 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I16: beats=1522 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I17: beats=1672 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I18: beats=3028 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I19: beats=2062 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I20: beats=2650 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I21: beats=2184 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I22: beats=3125 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I23: beats=2205 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I24: beats=2570 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I25: beats=1712 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I26: beats=1509 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I27: beats=2605 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I28: beats=1717 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I29: beats=2619 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I30: beats=2461 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I31: beats=3208 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I32: beats=1619 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I33: beats=1836 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I34: beats=1964 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I35: beats=3657 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I36: beats=3898 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I37: beats=2461 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I38: beats=2697 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I39: beats=1774 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I40: beats=2666 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I41: beats=1630 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I42: beats=3100 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I43: beats=2206 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I44: beats=2494 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I45: beats=1927 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I46: beats=2655 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I47: beats=1953 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I48: beats=2356 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I49: beats=2147 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I50: beats=2998 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I51: beats=2776 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I52: beats=1747 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I53: beats=2261 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I54: beats=2363 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I55: beats=2166 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I56: beats=1705 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I57: beats=2865 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I58: beats=2324 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I59: beats=2148 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I60: beats=2474 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I61: beats=1453 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I62: beats=2257 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I63: beats=1986 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I64: beats=1909 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I65: beats=2660 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I66: beats=2339 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I67: beats=2973 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I68: beats=2644 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I69: beats=2167 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I70: beats=1666 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I71: beats=1670 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I72: beats=2269 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I73: beats=1992 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I74: beats=2356 lead_primary=II lead_secondary=V1\n",
            "[OK] INCART I75: beats=2095 lead_primary=II lead_secondary=V1\n",
            "INCART shapes: (175613, 216, 2) (175613,)\n",
            "\n",
            "INCART Train (pre-SMOTE)\n",
            "  class   count\n",
            "0     N  121314\n",
            "1     S    1819\n",
            "2     V   14238\n",
            "\n",
            "INCART Test\n",
            "  class  count\n",
            "0     N  32330\n",
            "1     S    140\n",
            "2     V   5772\n",
            "\n",
            "INCART Train (post-SMOTE)\n",
            "  class   count\n",
            "0     N  121314\n",
            "1     S  121314\n",
            "2     V  121314\n",
            "Saved -> incart_3class_2lead.npz\n",
            "Epoch 1/25\n",
            "2417/2417 - 163s - 68ms/step - accuracy: 0.7777 - loss: 0.5142 - val_accuracy: 0.3019 - val_loss: 1.1727\n",
            "Epoch 2/25\n",
            "2417/2417 - 204s - 84ms/step - accuracy: 0.8250 - loss: 0.4094 - val_accuracy: 0.6472 - val_loss: 0.7048\n",
            "Epoch 3/25\n",
            "2417/2417 - 165s - 68ms/step - accuracy: 0.8413 - loss: 0.3699 - val_accuracy: 0.5135 - val_loss: 0.9205\n",
            "Epoch 4/25\n",
            "2417/2417 - 201s - 83ms/step - accuracy: 0.8511 - loss: 0.3482 - val_accuracy: 0.7264 - val_loss: 0.5746\n",
            "Epoch 5/25\n",
            "2417/2417 - 189s - 78ms/step - accuracy: 0.8571 - loss: 0.3328 - val_accuracy: 0.6340 - val_loss: 0.6773\n",
            "Epoch 6/25\n",
            "2417/2417 - 203s - 84ms/step - accuracy: 0.8634 - loss: 0.3187 - val_accuracy: 0.7321 - val_loss: 0.5921\n",
            "Epoch 7/25\n",
            "2417/2417 - 159s - 66ms/step - accuracy: 0.8673 - loss: 0.3102 - val_accuracy: 0.4939 - val_loss: 0.8905\n",
            "Epoch 8/25\n",
            "2417/2417 - 152s - 63ms/step - accuracy: 0.8714 - loss: 0.3012 - val_accuracy: 0.8042 - val_loss: 0.4485\n",
            "Epoch 9/25\n",
            "2417/2417 - 160s - 66ms/step - accuracy: 0.8737 - loss: 0.2952 - val_accuracy: 0.8547 - val_loss: 0.3406\n",
            "Epoch 10/25\n",
            "2417/2417 - 199s - 82ms/step - accuracy: 0.8769 - loss: 0.2869 - val_accuracy: 0.8315 - val_loss: 0.3994\n",
            "Epoch 11/25\n",
            "2417/2417 - 200s - 83ms/step - accuracy: 0.8794 - loss: 0.2810 - val_accuracy: 0.7141 - val_loss: 0.5719\n",
            "Epoch 12/25\n",
            "2417/2417 - 150s - 62ms/step - accuracy: 0.8807 - loss: 0.2776 - val_accuracy: 0.8447 - val_loss: 0.3865\n",
            "Epoch 13/25\n",
            "2417/2417 - 200s - 83ms/step - accuracy: 0.8832 - loss: 0.2718 - val_accuracy: 0.6497 - val_loss: 0.6349\n",
            "Epoch 14/25\n",
            "2417/2417 - 202s - 84ms/step - accuracy: 0.8849 - loss: 0.2671 - val_accuracy: 0.8656 - val_loss: 0.3406\n",
            "Epoch 15/25\n",
            "2417/2417 - 145s - 60ms/step - accuracy: 0.8851 - loss: 0.2654 - val_accuracy: 0.7922 - val_loss: 0.4429\n",
            "Epoch 16/25\n",
            "2417/2417 - 203s - 84ms/step - accuracy: 0.8886 - loss: 0.2605 - val_accuracy: 0.9112 - val_loss: 0.2327\n",
            "Epoch 17/25\n",
            "2417/2417 - 206s - 85ms/step - accuracy: 0.8891 - loss: 0.2574 - val_accuracy: 0.8406 - val_loss: 0.3620\n",
            "Epoch 18/25\n",
            "2417/2417 - 147s - 61ms/step - accuracy: 0.8914 - loss: 0.2537 - val_accuracy: 0.8631 - val_loss: 0.3248\n",
            "Epoch 19/25\n",
            "2417/2417 - 208s - 86ms/step - accuracy: 0.8918 - loss: 0.2518 - val_accuracy: 0.9324 - val_loss: 0.2051\n",
            "Epoch 20/25\n",
            "2417/2417 - 197s - 81ms/step - accuracy: 0.8931 - loss: 0.2482 - val_accuracy: 0.8551 - val_loss: 0.3367\n",
            "Epoch 21/25\n",
            "2417/2417 - 148s - 61ms/step - accuracy: 0.8935 - loss: 0.2469 - val_accuracy: 0.7743 - val_loss: 0.4658\n",
            "Epoch 22/25\n",
            "2417/2417 - 197s - 81ms/step - accuracy: 0.8945 - loss: 0.2444 - val_accuracy: 0.8821 - val_loss: 0.3142\n",
            "Epoch 23/25\n",
            "2417/2417 - 207s - 86ms/step - accuracy: 0.8967 - loss: 0.2404 - val_accuracy: 0.6156 - val_loss: 0.6814\n",
            "Epoch 24/25\n",
            "2417/2417 - 147s - 61ms/step - accuracy: 0.8966 - loss: 0.2389 - val_accuracy: 0.9167 - val_loss: 0.2251\n",
            "INCART Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N     0.8784    0.7324    0.7988     32330\n",
            "           S     0.0162    0.1143    0.0284       140\n",
            "           V     0.2395    0.4274    0.3070      5772\n",
            "\n",
            "    accuracy                         0.6841     38242\n",
            "   macro avg     0.3780    0.4247    0.3781     38242\n",
            "weighted avg     0.7788    0.6841    0.7217     38242\n",
            "\n",
            "Confusion Matrix:\n",
            "[[23678   825  7827]\n",
            " [  117    16     7]\n",
            " [ 3160   145  2467]]\n"
          ]
        }
      ],
      "source": [
        "# Load INCART using same functions (lead picking will choose II + V1/V5)\n",
        "inc_X, inc_y, inc_rec = load_dataset_from_folder(INCART_DIR, INCART_RECORDS, dataset_name=\"INCART\")\n",
        "print(\"INCART shapes:\", inc_X.shape, inc_y.shape)\n",
        "\n",
        "# Split by record\n",
        "inc_train_mask, inc_test_mask = record_wise_split(inc_rec)\n",
        "Xtr_inc, ytr_inc = inc_X[inc_train_mask], inc_y[inc_train_mask]\n",
        "Xte_inc, yte_inc = inc_X[inc_test_mask], inc_y[inc_test_mask]\n",
        "\n",
        "describe_distribution(ytr_inc, \"INCART Train (pre-SMOTE)\")\n",
        "describe_distribution(yte_inc, \"INCART Test\")\n",
        "\n",
        "# Apply SMOTE to train only\n",
        "if Xtr_inc.shape[0] > 0:\n",
        "    Xtr_inc_sm, ytr_inc_sm = apply_smote(Xtr_inc, ytr_inc)\n",
        "    describe_distribution(ytr_inc_sm, \"INCART Train (post-SMOTE)\")\n",
        "else:\n",
        "    Xtr_inc_sm, ytr_inc_sm = Xtr_inc, ytr_inc\n",
        "    print(\"[WARN] No INCART training beats; SMOTE skipped.\")\n",
        "\n",
        "# Save preprocessed datasets\n",
        "np.savez_compressed(\"incart_3class_2lead.npz\",\n",
        "                    X_train=Xtr_inc_sm, y_train=ytr_inc_sm,\n",
        "                    X_test=Xte_inc, y_test=yte_inc, rec_test=inc_rec[inc_test_mask])\n",
        "print(\"Saved -> incart_3class_2lead.npz\")\n",
        "\n",
        "# Build & train model (same architecture for comparability)\n",
        "inc_model = build_cnn_model(input_shape=(win_len, 2), num_classes=3)\n",
        "tb2 = tf.keras.callbacks.TensorBoard(log_dir=str(Path(LOGDIR) / \"incart\"), histogram_freq=0)\n",
        "es2 = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "if Xtr_inc_sm.shape[0] > 0:\n",
        "    inc_hist = inc_model.fit(\n",
        "        Xtr_inc_sm, one_hot(ytr_inc_sm, 3),\n",
        "        validation_split=0.15,\n",
        "        epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "        callbacks=[tb2, es2], verbose=2\n",
        "    )\n",
        "else:\n",
        "    print(\"[WARN] INCART training skipped (no data).\")\n",
        "\n",
        "# Evaluate\n",
        "if Xte_inc.shape[0] > 0:\n",
        "    yhat = inc_model.predict(Xte_inc, verbose=0).argmax(axis=1)\n",
        "    print(\"INCART Classification Report:\")\n",
        "    print(classification_report(yte_inc, yhat, target_names=CLASS_ORDER, digits=4))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(yte_inc, yhat))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zm-x_x5bwD6e"
      },
      "id": "Zm-x_x5bwD6e"
    },
    {
      "cell_type": "markdown",
      "id": "eddf8503",
      "metadata": {
        "id": "eddf8503"
      },
      "source": [
        "## Optional: Cross-Dataset Evaluation\n",
        "\n",
        "Evaluate how each model generalizes across datasets (domain shift)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50da2982",
      "metadata": {
        "id": "50da2982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6c6dc3-9671-46c6-97c0-46fd2ea78671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MIT-BIH model on INCART Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N     0.8632    0.5135    0.6439     32330\n",
            "           S     0.0026    0.1786    0.0051       140\n",
            "           V     0.2105    0.3392    0.2598      5772\n",
            "\n",
            "    accuracy                         0.4860     38242\n",
            "   macro avg     0.3588    0.3438    0.3029     38242\n",
            "weighted avg     0.7615    0.4860    0.5836     38242\n",
            "\n",
            "INCART model on MIT-BIH Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N     0.9047    0.7885    0.8426     20831\n",
            "           S     0.0112    0.1827    0.0211       197\n",
            "           V     0.2841    0.2393    0.2598      2211\n",
            "\n",
            "    accuracy                         0.7311     23239\n",
            "   macro avg     0.4000    0.4035    0.3745     23239\n",
            "weighted avg     0.8380    0.7311    0.7802     23239\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MIT-BIH model on INCART test\n",
        "if 'mit_model' in globals() and 'Xte_inc' in globals() and Xte_inc.shape[0] > 0:\n",
        "    yhat = mit_model.predict(Xte_inc, verbose=0).argmax(axis=1)\n",
        "    print(\"MIT-BIH model on INCART Test:\")\n",
        "    print(classification_report(yte_inc, yhat, target_names=CLASS_ORDER, digits=4))\n",
        "\n",
        "# INCART model on MIT-BIH test\n",
        "if 'inc_model' in globals() and 'Xte_mit' in globals() and Xte_mit.shape[0] > 0:\n",
        "    yhat = inc_model.predict(Xte_mit, verbose=0).argmax(axis=1)\n",
        "    print(\"INCART model on MIT-BIH Test:\")\n",
        "    print(classification_report(yte_mit, yhat, target_names=CLASS_ORDER, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b319e60",
      "metadata": {
        "id": "8b319e60"
      },
      "source": [
        "## Save Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82ca117e",
      "metadata": {
        "id": "82ca117e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7c9fc6-18ad-4fd2-8863-c648a6125e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> mitbih_3class_2lead_cnn.keras\n",
            "Saved -> incart_3class_2lead_cnn.keras\n"
          ]
        }
      ],
      "source": [
        "# Save models after training (if trained)\n",
        "try:\n",
        "    mit_model.save(\"mitbih_3class_2lead_cnn.keras\")\n",
        "    print(\"Saved -> mitbih_3class_2lead_cnn.keras\")\n",
        "except Exception as e:\n",
        "    print(\"MIT-BIH model not saved (maybe no training ran):\", e)\n",
        "\n",
        "try:\n",
        "    inc_model.save(\"incart_3class_2lead_cnn.keras\")\n",
        "    print(\"Saved -> incart_3class_2lead_cnn.keras\")\n",
        "except Exception as e:\n",
        "    print(\"INCART model not saved (maybe no training ran):\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51188a04",
      "metadata": {
        "id": "51188a04"
      },
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}